{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites\n",
    "1. Tokenize and preprocess the RELISH and TREC data sets.\n",
    "    - Use the [medline-preprocessing](https://github.com/zbmed-semtec/medline-preprocessing) module to retrieve both the RELISH and TREC data sets.\n",
    "    - Make sure to tokenize and preprocess it and save both data sets as .npy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.chdir('../Code')\n",
    "from Process import prepareFromNPY, generateWord2VecModel, generateDocumentEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Strategy\n",
    "1. Retrieve the PMIDs, Titles and Abstracts seperately from each data set.\n",
    "2. Train a word2vec model using either the RELISH or TREC data set.\n",
    "    - We use gensim to train the model.\n",
    "    - Outputs a .model file.\n",
    "    - Uses pickle to split the .model file into different files incase it surpasses a size treshhold.\n",
    "3. Generate the document embeddings from either the RELISH or TREC data set.\n",
    "    - Retrieve word embeddings of each token using the word2vec model.\n",
    "    - Calculate the document embeddings for each document using the centroids function,\n",
    "    taking the average of all word embeddings embeddings.\n",
    "    - A document consists of a pair of title and abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Retrieve the PMIDs, Titles and Abstracts seperately from each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the RELISH .npy file.\n",
    "pmidRELISH, titleRELISH, abstractRELISH = prepareFromNPY(\"../Data/RELISH/Tokenized_Input/RELISH_Tokenized_Sample.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train a word2vec model using either the RELISH or TREC data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the word2vec model using gensim.\n",
    "generateWord2VecModel(titleRELISH, abstractRELISH, \"../Data/RELISH/Output/word2vecModel/model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate the document embeddings from either the RELISH or TREC data set and save as .npy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate document embeddings for each PMID.\n",
    "generateDocumentEmbeddings(pmidRELISH, titleRELISH, abstractRELISH, directoryOut=\"../Data/RELISH/Output/DocumentEmbeddings\", gensimModelPath=\"../Data/RELISH/Output/word2vecModel/model.model\", saveAs='numpy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively save the embeddings as a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate document embeddings for each PMID.\n",
    "generateDocumentEmbeddings(pmidRELISH, titleRELISH, abstractRELISH, directoryOut=\"../Data/RELISH/Output/DocumentEmbeddings\", gensimModelPath=\"../Data/RELISH/Output/word2vecModel/model.model\", saveAs='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the embeddings and calculating cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access embeddings via .npy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmidA = 17928366\n",
    "pmidB = 22569528\n",
    "embeddingA = np.load(f'../Data/RELISH/Output/DocumentEmbeddings/{pmidA}.npy', allow_pickle=True)\n",
    "embeddingB = np.load(f'../Data/RELISH/Output/DocumentEmbeddings/{pmidB}.npy', allow_pickle=True)\n",
    "print(f'The cosine similarity score between the PMIDs {pmidA} and {pmidB}: {round((1 - spatial.distance.cosine(embeddingA, embeddingB)), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access embeddings via pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../Data/RELISH/Output/DocumentEmbeddings/embeddings.pkl\", compression='infer', storage_options=None)\n",
    "embeddingA = df['embeddings'][0]\n",
    "embeddingB = df['embeddings'][1]\n",
    "print(f\"The cosine similarity score between the PMIDs {df['pmids'][0]} and {df['pmids'][1]}: {round((1 - spatial.distance.cosine(embeddingA, embeddingB)), 2)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
