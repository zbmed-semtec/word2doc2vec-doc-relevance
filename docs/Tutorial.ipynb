{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites\n",
    "1. Tokenize and preprocess the RELISH and TREC data sets.\n",
    "    - Use the [medline-preprocessing](https://github.com/zbmed-semtec/medline-preprocessing) module to retrieve both the RELISH and TREC data sets.\n",
    "    - Make sure to tokenize and preprocess it and save both data sets as .npy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.chdir('../Code')\n",
    "from generate_embeddings import prepare_from_npy, generate_Word2Vec_model, generate_document_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Strategy\n",
    "1. Retrieve the PMIDs, Titles and Abstracts seperately from each data set.\n",
    "2. Train a word2vec model using either the RELISH or TREC data set.\n",
    "    - We use gensim to train the model.\n",
    "    - Outputs a .model file.\n",
    "    - Uses pickle to split the .model file into different files incase it surpasses a size treshhold.\n",
    "3. Generate the document embeddings from either the RELISH or TREC data set.\n",
    "    - Retrieve word embeddings of each token using the word2vec model.\n",
    "    - Calculate the document embeddings for each document using the centroids function,\n",
    "    taking the average of all word embeddings embeddings.\n",
    "    - A document consists of a pair of title and abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Retrieve the PMIDs, Titles and Abstracts seperately from each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse the RELISH .npy file.\n",
    "pmidRELISH, docRELISH = prepare_from_npy(\"../data/RELISH/Tokenized_Input/RELISH_Tokenized_Sample.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train a word2vec model using either the RELISH or TREC data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the word2vec model using gensim.\n",
    "params = {'vector_size':200, 'epochs':5, 'window':5, 'min_count':2, 'workers':4}\n",
    "generate_Word2Vec_model(docRELISH, pmidRELISH, params, \"../data/RELISH/model.model\", False)\n",
    "#generate_Word2Vec_model(article_doc: list, pmids: list, params: list, filepath_out: str, use_pretrained: bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate the document embeddings from either the RELISH or TREC data set and save as .npy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate document embeddings for each PMID.\n",
    "generate_document_embeddings(pmidRELISH, docRELISH, directory_out=\"../data/RELISH/\", gensim_model_path=\"../data/RELISH/model.model\", param_iteration=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access embeddings via pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/RELISH/0/embeddings.pkl\", compression='infer', storage_options=None)\n",
    "embeddingA = df['embeddings'][0]\n",
    "embeddingB = df['embeddings'][1]\n",
    "print(f\"The cosine similarity score between the PMIDs {df['pmids'][0]} and {df['pmids'][1]}: {round((1 - spatial.distance.cosine(embeddingA, embeddingB)), 2)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
